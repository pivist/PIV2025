{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a09f2d23-5a7b-44eb-8fd4-b2734fe3963e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import torch\n",
    "from mapanything.models import MapAnything\n",
    "from mapanything.utils.image import load_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f5e55f0-6a83-4fe8-9d66-ae18fee5e059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained dinov2_vitl14 from torch hub\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/jpc/.cache/torch/hub/facebookresearch_dinov2_main\n"
     ]
    }
   ],
   "source": [
    "# Get inference device\n",
    "device = \"cpu\" \n",
    "\n",
    "# Init model - This requires internet access or the huggingface hub cache to be pre-downloaded\n",
    "# For Apache 2.0 license model, use \"facebook/map-anything-apache\"\n",
    "model = MapAnything.from_pretrained(\"facebook/map-anything\").to(device)\n",
    "\n",
    "# Load and preprocess images from a folder or list of paths\n",
    "#images = [\"/Users/jpc/Nextcloud/IST/Escolaridade/PIV2025/Datasets/TaagPIV/20251028_165814.jpg\" ] # or [\"path/to/img1.jpg\", \"path/to/img2.jpg\", ...]\n",
    "images = \"/Users/jpc/Nextcloud/IST/Escolaridade/PIV2025/AulasPraticas/aula7_3D_registration/plondres\" # or [\"path/to/img1.jpg\", \"path/to/img2.jpg\", ...]\n",
    "views = load_images(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2f291a8-ae40-4149-8128-646f3b1306f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================\n",
    "# 1. Scan image directory\n",
    "# ============================================================\n",
    "\n",
    "def scan_image_directory(\n",
    "    image_dir,\n",
    "    extensions=(\".jpg\", \".jpeg\", \".png\")\n",
    "):\n",
    "    \"\"\"\n",
    "    Scan directory and return sorted list of image paths.\n",
    "    \"\"\"\n",
    "    image_paths = [\n",
    "        os.path.join(image_dir, f)\n",
    "        for f in os.listdir(image_dir)\n",
    "        if f.lower().endswith(extensions)\n",
    "    ]\n",
    "\n",
    "    if not image_paths:\n",
    "        raise ValueError(f\"No images found in {image_dir}\")\n",
    "\n",
    "    image_paths.sort()\n",
    "    return image_paths\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2. MapAnything Images-Only Inference\n",
    "# ============================================================\n",
    "\n",
    "def run_mapanything_images_only(image_paths):\n",
    "    \"\"\"\n",
    "    Call MapAnything Images-Only Inference.\n",
    "    \"\"\"\n",
    "    views = load_images(images)\n",
    "    # Run inference\n",
    "    predictions = model.infer(\n",
    "        views,                            # Input views\n",
    "        memory_efficient_inference=False, # Trades off speed for more views (up to 2000 views on 140 GB)\n",
    "        use_amp=True,                     # Use mixed precision inference (recommended)\n",
    "        amp_dtype=\"bf16\",                 # bf16 inference (recommended; falls back to fp16 if bf16 not supported)\n",
    "        apply_mask=True,                  # Apply masking to dense geometry outputs\n",
    "        mask_edges=True,                  # Remove edge artifacts by using normals and depth\n",
    "        apply_confidence_mask=False,      # Filter low-confidence regions\n",
    "        confidence_percentile=10,         # Remove bottom 10 percentile confidence pixels\n",
    "    )\n",
    "        \n",
    "    d=[]\n",
    "    for i, pred in enumerate(predictions):\n",
    "        d.append({\n",
    "            key: value.detach().cpu().numpy().squeeze() for key, value in pred.items()\n",
    "        })\n",
    "    return(d)\n",
    "\n",
    "# ============================================================\n",
    "# 3. Utilities\n",
    "# ============================================================\n",
    "\n",
    "def _save_rgb_image(img, path):\n",
    "    if img.ndim == 3 and img.shape[0] == 3:\n",
    "        img = np.transpose(img, (1, 2, 0))\n",
    "\n",
    "    img = img.astype(np.float32)\n",
    "    if img.max() <= 1.0:\n",
    "        img *= 255.0\n",
    "\n",
    "    img = np.clip(img, 0, 255).astype(np.uint8)\n",
    "    img_bgr = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "    cv2.imwrite(path, img_bgr)\n",
    "\n",
    "\n",
    "def _save_depth_mat(depth, K, path):\n",
    "    sio.savemat(\n",
    "        path,\n",
    "        {\n",
    "            \"depth\": depth.astype(np.float32),\n",
    "            \"K\": K.astype(np.float32),\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4. Template + sequence generation\n",
    "# ============================================================\n",
    "\n",
    "def generate_template(pred0, template_dir):\n",
    "    os.makedirs(template_dir, exist_ok=True)\n",
    "\n",
    "    _save_rgb_image(\n",
    "        pred0[\"img_no_norm\"],\n",
    "        os.path.join(template_dir, \"templatergb.jpg\"),\n",
    "    )\n",
    "\n",
    "    _save_depth_mat(\n",
    "        pred0[\"depth_z\"],\n",
    "        pred0[\"intrinsics\"],\n",
    "        os.path.join(template_dir, \"templatedepth.mat\"),\n",
    "    )\n",
    "\n",
    "\n",
    "def generate_sequence(preds, sequence_dir, base_name=\"frame\"):\n",
    "    os.makedirs(sequence_dir, exist_ok=True)\n",
    "\n",
    "    for i, pred in enumerate(preds):\n",
    "        idx_str = f\"{i:04d}\"\n",
    "\n",
    "        _save_rgb_image(\n",
    "            pred[\"img_no_norm\"],\n",
    "            os.path.join(sequence_dir, f\"{base_name}_{idx_str}.jpg\"),\n",
    "        )\n",
    "\n",
    "        _save_depth_mat(\n",
    "            pred[\"depth_z\"],\n",
    "            pred[\"intrinsics\"],\n",
    "            os.path.join(sequence_dir, f\"{base_name}_{idx_str}.mat\"),\n",
    "        )\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 5. ONE-CALL dataset generation\n",
    "# ============================================================\n",
    "\n",
    "def generate_full_dataset(\n",
    "    image_dir,\n",
    "    output_root,\n",
    "    base_name=\"frame\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate full assignment dataset from an image directory.\n",
    "    \"\"\"\n",
    "\n",
    "    # ---- Scan directory ----\n",
    "    image_paths = scan_image_directory(image_dir)\n",
    "\n",
    "    # ---- Run MapAnything ----\n",
    "    preds = run_mapanything_images_only(image_paths)\n",
    "\n",
    "    if len(preds) < 2:\n",
    "        raise ValueError(\"Need at least 2 images for template + sequence\")\n",
    "\n",
    "    # ---- Output structure ----\n",
    "    template_dir = os.path.join(output_root, \"template\")\n",
    "    sequence_dir = os.path.join(output_root, \"sequence\")\n",
    "    ground_truth = os.path.join(output_root, \"gtruth\")\n",
    "    os.makedirs(ground_truth, exist_ok=True)\n",
    "    sio.savemat(os.path.join(ground_truth,\"alldata.mat\"),{\"predicts\":preds})\n",
    "    \n",
    "    # ---- Template from first frame ----\n",
    "    generate_template(preds[0], template_dir)\n",
    "\n",
    "    # ---- Sequence from remaining frames ----\n",
    "    generate_sequence(\n",
    "        preds=preds[1:],\n",
    "        sequence_dir=sequence_dir,\n",
    "        base_name=base_name,\n",
    "    )\n",
    "\n",
    "    print(\"Dataset generation complete\")\n",
    "    print(f\"Template directory : {template_dir}\")\n",
    "    print(f\"Sequence directory : {sequence_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d43670a-4a14-4d84-b1e1-11ed6403f376",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jpc/Nextcloud/IST/code/aisp/map-anything/mapanything/models/mapanything/model.py:2052: UserWarning: bf16 is not supported on this device. Using fp16 instead.\n",
      "  warnings.warn(\n",
      "/Users/jpc/piton/lib/python3.13/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset generation complete\n",
      "Template directory : /Users/jpc/Nextcloud/IST/Escolaridade/PIV2025/AulasPraticas/aula7_3D_registration/plondres/plondres/template\n",
      "Sequence directory : /Users/jpc/Nextcloud/IST/Escolaridade/PIV2025/AulasPraticas/aula7_3D_registration/plondres/plondres/sequence\n"
     ]
    }
   ],
   "source": [
    "generate_full_dataset(\n",
    "    image_dir= \"/Users/jpc/Nextcloud/IST/Escolaridade/PIV2025/AulasPraticas/aula7_3D_registration/plondres/\",\n",
    "    output_root=\"/Users/jpc/Nextcloud/IST/Escolaridade/PIV2025/AulasPraticas/aula7_3D_registration/plondres/plondres\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
