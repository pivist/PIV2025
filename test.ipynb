{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b7115d-3bfc-4324-9d0f-22f6ee540b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional config for better memory efficiency\n",
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "#import k3d\n",
    "\n",
    "# Required imports\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4e3742-c7d1-42e7-a692-f9a8ee35a214",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mapanything.models import MapAnything\n",
    "from mapanything.utils.image import load_images\n",
    "\n",
    "# Init model - This requires internet access or the huggingface hub cache to be pre-downloaded\n",
    "# For Apache 2.0 license model, use \"facebook/map-anything-apache\"\n",
    "model = MapAnything.from_pretrained(\"facebook/map-anything\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa7ab5d-7a5c-4533-b9c2-57bf343ec115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess images from a folder or list of paths\n",
    "images = \"/home/jovyan/work/Nextcloud/Nextcloudprintart/IST/Escolaridade/PIV2025/images\"  # or [\"path/to/img1.jpg\", \"path/to/img2.jpg\", ...]\n",
    "views = load_images(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ce45c6-3ea8-4459-8e37-1e70cca11e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference\n",
    "predictions = model.infer(\n",
    "    views,                            # Input views\n",
    "    memory_efficient_inference=False, # Trades off speed for more views (up to 2000 views on 140 GB)\n",
    "    use_amp=True,                     # Use mixed precision inference (recommended)\n",
    "    amp_dtype=\"bf16\",                 # bf16 inference (recommended; falls back to fp16 if bf16 not supported)\n",
    "    apply_mask=True,                  # Apply masking to dense geometry outputs\n",
    "    mask_edges=True,                  # Remove edge artifacts by using normals and depth\n",
    "    apply_confidence_mask=False,      # Filter low-confidence regions\n",
    "    confidence_percentile=10,         # Remove bottom 10 percentile confidence pixels\n",
    ")\n",
    "\n",
    "# Access results for each view - Complete list of metric outputs\n",
    "for i, pred in enumerate(predictions):\n",
    "    # Geometry outputs\n",
    "    pts3d = pred[\"pts3d\"]                     # 3D points in world coordinates (B, H, W, 3)\n",
    "    pts3d_cam = pred[\"pts3d_cam\"]             # 3D points in camera coordinates (B, H, W, 3)\n",
    "    depth_z = pred[\"depth_z\"]                 # Z-depth in camera frame (B, H, W, 1)\n",
    "    depth_along_ray = pred[\"depth_along_ray\"] # Depth along ray in camera frame (B, H, W, 1)\n",
    "\n",
    "    # Camera outputs\n",
    "    ray_directions = pred[\"ray_directions\"]   # Ray directions in camera frame (B, H, W, 3)\n",
    "    intrinsics = pred[\"intrinsics\"]           # Recovered pinhole camera intrinsics (B, 3, 3)\n",
    "    camera_poses = pred[\"camera_poses\"]       # OpenCV (+X - Right, +Y - Down, +Z - Forward) cam2world poses in world frame (B, 4, 4)\n",
    "    cam_trans = pred[\"cam_trans\"]             # OpenCV (+X - Right, +Y - Down, +Z - Forward) cam2world translation in world frame (B, 3)\n",
    "    cam_quats = pred[\"cam_quats\"]             # OpenCV (+X - Right, +Y - Down, +Z - Forward) cam2world quaternion in world frame (B, 4)\n",
    "\n",
    "    # Quality and masking\n",
    "    confidence = pred[\"conf\"]                 # Per-pixel confidence scores (B, H, W)\n",
    "    mask = pred[\"mask\"]                       # Combined validity mask (B, H, W, 1)\n",
    "    non_ambiguous_mask = pred[\"non_ambiguous_mask\"]                # Non-ambiguous regions (B, H, W)\n",
    "    non_ambiguous_mask_logits = pred[\"non_ambiguous_mask_logits\"]  # Mask logits (B, H, W)\n",
    "\n",
    "    # Scaling\n",
    "    metric_scaling_factor = pred[\"metric_scaling_factor\"]  # Applied metric scaling (B,)\n",
    "\n",
    "    # Original input\n",
    "    img_no_norm = pred[\"img_no_norm\"]         # Denormalized input images for visualization (B, H, W, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0acca6-4c7a-46cd-8ae9-9ea6cb29b406",
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence = pred[\"conf\"]                 # Per-pixel confidence scores (B, H, W)\n",
    "mask = pred[\"mask\"]                       # Combined validity mask (B, H, W, 1)\n",
    "non_ambiguous_mask = pred[\"non_ambiguous_mask\"]                # Non-ambiguous regions (B, H, W)\n",
    "non_ambiguous_mask_logits = pred[\"non_ambiguous_mask_logits\"]  # Mask logits (B, H, W)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128b8ead-03d5-4c4f-b87b-3f12e47ef579",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26003a14-6798-4a5e-b99e-211a5b0138c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.io import savemat\n",
    "savemat(\"/Users/jpc/Downloads/PIV2025/images/taag.mat\",{\"many\":predictions})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e294c6b5-247f-4790-9129-5e8db7d88dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import k3d\n",
    "plot = k3d.plot()\n",
    "plot += k3d.line([[0, 0, 0],\n",
    "                 [1, 1, 1]])\n",
    "\n",
    "plot.display()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fc275b-8909-4a99-b8e7-1eb1b926f015",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b61f1a8-47f7-43fb-b0f7-2e5ad36d572f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapy as media\n",
    "import numpy as np\n",
    "\n",
    "url = 'https://github.com/hhoppe/data/raw/main/video.mp4'\n",
    "video = media.read_video(url)\n",
    "print(video.shape, video.dtype)  # It is a numpy array.\n",
    "print(video.metadata.fps)  # The 'metadata' attribute includes framerate.\n",
    "media.show_video(video)  # Play the video using the retrieved framerate.\n",
    "\n",
    "media.show_images(video, height=80, columns=4)  # Show frames side-by-side.\n",
    "\n",
    "video = media.moving_circle((128, 128), num_images=10)\n",
    "media.show_video(video, fps=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
